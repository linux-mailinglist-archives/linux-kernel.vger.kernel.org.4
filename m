Return-Path: <linux-kernel-owner@vger.kernel.org>
X-Original-To: lists+linux-kernel@lfdr.de
Delivered-To: lists+linux-kernel@lfdr.de
Received: from out1.vger.email (out1.vger.email [IPv6:2620:137:e000::1:20])
	by mail.lfdr.de (Postfix) with ESMTP id 04BBF69C6F5
	for <lists+linux-kernel@lfdr.de>; Mon, 20 Feb 2023 09:48:48 +0100 (CET)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S231287AbjBTIsP (ORCPT <rfc822;lists+linux-kernel@lfdr.de>);
        Mon, 20 Feb 2023 03:48:15 -0500
Received: from lindbergh.monkeyblade.net ([23.128.96.19]:60460 "EHLO
        lindbergh.monkeyblade.net" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S230508AbjBTIro (ORCPT
        <rfc822;linux-kernel@vger.kernel.org>);
        Mon, 20 Feb 2023 03:47:44 -0500
Received: from dfw.source.kernel.org (dfw.source.kernel.org [IPv6:2604:1380:4641:c500::1])
        by lindbergh.monkeyblade.net (Postfix) with ESMTPS id 450D1C16F
        for <linux-kernel@vger.kernel.org>; Mon, 20 Feb 2023 00:47:42 -0800 (PST)
Received: from smtp.kernel.org (relay.kernel.org [52.25.139.140])
        (using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
        (No client certificate requested)
        by dfw.source.kernel.org (Postfix) with ESMTPS id E1FE960CF7
        for <linux-kernel@vger.kernel.org>; Mon, 20 Feb 2023 08:47:41 +0000 (UTC)
Received: by smtp.kernel.org (Postfix) with ESMTPSA id 3D9EEC433D2;
        Mon, 20 Feb 2023 08:47:41 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
        s=k20201202; t=1676882861;
        bh=DmuaPjOTORNSh9WvrC/jxjMBglQwDodpPLZaRxHc1iE=;
        h=Date:From:To:Cc:Subject:In-Reply-To:References:From;
        b=RBKsNFWNlxx9RBbi5UH/AXVHT9I3FPU2tdAcGOslxCwxcyHm/HnvCHUGrNVe/2qTK
         5zxDx66DW0f7/awhbPBUZ4o3O46iwo18KNJuZQKVp9L1AL6l4D7VUpRB8JpGYTwohs
         je6F3NbztfXjQK2TWLMtGthFf95Dc6hQHFJ4vtAYCmf/kmzzjWXdfMSBqK9uRAzpSH
         UIeneztEhXvlaMi5/pbGaryvlPwwMO9b/JVxaUZgBW5bwnSSqBXEUBZFHFrMCrjvNV
         DaRjDyvkeTsm5NfBBL3LA9bk2D1pV5vpoY0slkCImKo4fQsXoSXAMqTwOIo2e46k+C
         bt48rgZ9L2o2Q==
Received: from sofa.misterjones.org ([185.219.108.64] helo=goblin-girl.misterjones.org)
        by disco-boy.misterjones.org with esmtpsa  (TLS1.3) tls TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
        (Exim 4.95)
        (envelope-from <maz@kernel.org>)
        id 1pU1pi-00BjuK-OR;
        Mon, 20 Feb 2023 08:47:38 +0000
Date:   Mon, 20 Feb 2023 08:47:38 +0000
Message-ID: <86h6vgyb85.wl-maz@kernel.org>
From:   Marc Zyngier <maz@kernel.org>
To:     "Raghavendra, Vignesh" <vigneshr@ti.com>
Cc:     Nishanth Menon <nm@ti.com>, Tero Kristo <kristo@kernel.org>,
        Santosh Shilimkar <ssantosh@kernel.org>,
        Thomas Gleixner <tglx@linutronix.de>,
        <linux-arm-kernel@lists.infradead.org>,
        <linux-kernel@vger.kernel.org>
Subject: Re: [RFC PATCH 2/2] irqchip: irq-ti-sci-inta: Introduce IRQ affinity support
In-Reply-To: <cba927be-a83c-d397-100c-03c89b5696ec@ti.com>
References: <20230122081607.959474-1-vigneshr@ti.com>
        <20230122081607.959474-3-vigneshr@ti.com>
        <86y1ppl6pl.wl-maz@kernel.org>
        <cba927be-a83c-d397-100c-03c89b5696ec@ti.com>
User-Agent: Wanderlust/2.15.9 (Almost Unreal) SEMI-EPG/1.14.7 (Harue)
 FLIM-LB/1.14.9 (=?UTF-8?B?R29qxY0=?=) APEL-LB/10.8 EasyPG/1.0.0 Emacs/28.2
 (aarch64-unknown-linux-gnu) MULE/6.0 (HANACHIRUSATO)
MIME-Version: 1.0 (generated by SEMI-EPG 1.14.7 - "Harue")
Content-Type: text/plain; charset=US-ASCII
X-SA-Exim-Connect-IP: 185.219.108.64
X-SA-Exim-Rcpt-To: vigneshr@ti.com, nm@ti.com, kristo@kernel.org, ssantosh@kernel.org, tglx@linutronix.de, linux-arm-kernel@lists.infradead.org, linux-kernel@vger.kernel.org
X-SA-Exim-Mail-From: maz@kernel.org
X-SA-Exim-Scanned: No (on disco-boy.misterjones.org); SAEximRunCond expanded to false
X-Spam-Status: No, score=-4.4 required=5.0 tests=BAYES_00,DKIMWL_WL_HIGH,
        DKIM_SIGNED,DKIM_VALID,DKIM_VALID_AU,DKIM_VALID_EF,RCVD_IN_DNSWL_MED,
        SPF_HELO_NONE,SPF_PASS autolearn=ham autolearn_force=no version=3.4.6
X-Spam-Checker-Version: SpamAssassin 3.4.6 (2021-04-09) on
        lindbergh.monkeyblade.net
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org

On Fri, 27 Jan 2023 17:53:55 +0000,
"Raghavendra, Vignesh" <vigneshr@ti.com> wrote:
>

[...]

> >> @@ -504,11 +509,45 @@ static void ti_sci_inta_ack_irq(struct irq_data *data)
> >>  		ti_sci_inta_manage_event(data, VINT_STATUS_OFFSET);
> >>  }
> >>  
> >> +#ifdef CONFIG_SMP
> >> +static int ti_sci_inta_set_affinity(struct irq_data *d,
> >> +				    const struct cpumask *mask_val, bool force)
> >> +{
> >> +	struct ti_sci_inta_event_desc *event_desc;
> >> +	struct ti_sci_inta_vint_desc *vint_desc;
> >> +	struct irq_data *parent_irq_data;
> >> +
> >> +	if (cpumask_equal(irq_data_get_effective_affinity_mask(d), mask_val))
> >> +		return 0;
> >> +
> >> +	event_desc = irq_data_get_irq_chip_data(d);
> >> +	if (event_desc) {
> >> +		vint_desc = to_vint_desc(event_desc, event_desc->vint_bit);
> >> +
> >> +		/*
> >> +		 * Cannot set affinity if there is more than one event
> >> +		 * mapped to same VINT
> >> +		 */
> >> +		if (bitmap_weight(vint_desc->event_map, MAX_EVENTS_PER_VINT) > 1)
> >> +			return -EINVAL;
> >> +
> >> +		vint_desc->affinity_managed = true;
> >> +
> >> +		irq_data_update_effective_affinity(d, mask_val);
> >> +		parent_irq_data = irq_get_irq_data(vint_desc->parent_virq);
> >> +		if (parent_irq_data->chip->irq_set_affinity)
> >> +			return parent_irq_data->chip->irq_set_affinity(parent_irq_data, mask_val, force);
> > 
> > This looks completely wrong.
> > 
> > You still have a chained irqchip on all paths, and have to do some
> > horrible probing to work out:
> > 
> > - which parent interrupt this is
> > 
> > - how many interrupts are connected to it
> > 
> > And then the fun begins:
> > 
> > - You have one interrupt that is standalone, so its affinity can be
> >   moved
> > 
> > - An unrelated driver gets probed, and one of its interrupts gets
> >   lumped together with the one above
> > 
> > - Now it cannot be moved anymore, and userspace complains
> > 
> > The rule is very simple: chained irqchip, no affinity management.
> > Either you reserve a poll of direct interrupts that have affinity
> 
> This is what I am trying to accomplish, that is, reserve a pool of
> direct interrupts that can be used by certain drivers that require IRQ
> steering for performance. But I don't see a way to indicate from client
> drivers to allocate from this reserved pool (there is no hint in
> request_irq() call that ends up in .irq_request_resources() that I can use)
> 
> I can try and virtually split INTA into two irqchips perhaps, with one
> part modeled as chained irqchip and other as stacked for the reserved
> pool (and would have to spawn of two child msi-domains I presume).
> But, there is only one DT node for this irqchip and thus clients cannot
> request IRQ for reserved pool.

I don't see why DT should be aware of this. You only need to decide at
allocation time which one is where, and plug it at the right level.

And you probably only need *one* chained interrupt that muxes
everything that cannot be allocated direct path.

> Wondering if you have any pointers here?

I don't. But this shouldn't be too hard to bolt onto the existing
framework.

	M.

-- 
Without deviation from the norm, progress is not possible.
